{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fdd0bcb",
   "metadata": {},
   "source": [
    "# [STARTER] Udaplay Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9325b035",
   "metadata": {},
   "source": [
    "## Part 02 - Agent\n",
    "\n",
    "In this part of the project, you'll use your VectorDB to be part of your Agent as a tool.\n",
    "\n",
    "You're building UdaPlay, an AI Research Agent for the video game industry. The agent will:\n",
    "1. Answer questions using internal knowledge (RAG)\n",
    "2. Search the web when needed\n",
    "3. Maintain conversation state\n",
    "4. Return structured outputs\n",
    "5. Store useful information for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b42de90",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "fd10c06e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T10:31:17.684766Z",
     "start_time": "2025-12-02T10:31:13.800302Z"
    }
   },
   "source": [
    "# Import tools and libraries\n",
    "from dotenv import load_dotenv\n",
    "from tavily import TavilyClient\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "import chromadb\n",
    "from lib.tooling import tool\n",
    "# from langchain.tools import tool\n",
    "\n",
    "from lib.agents import Agent"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "87e465d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T10:31:18.304835Z",
     "start_time": "2025-12-02T10:31:18.301472Z"
    }
   },
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "27de4729",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab2dac",
   "metadata": {},
   "source": [
    "Build at least 3 tools:\n",
    "- retrieve_game: To search the vector DB\n",
    "- evaluate_retrieval: To assess the retrieval performance\n",
    "- game_web_search: If no good, search the web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f14cd",
   "metadata": {},
   "source": [
    "#### Retrieve Game Tool"
   ]
  },
  {
   "cell_type": "code",
   "id": "b25c36dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T10:31:18.868455Z",
     "start_time": "2025-12-02T10:31:18.752437Z"
    }
   },
   "source": [
    "\n",
    "# ------------------------------\n",
    "# Chroma setup\n",
    "# ------------------------------\n",
    "chroma_client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "\n",
    "# ------------------------------\n",
    "# RETRIEVE_GAME TOOL\n",
    "# ------------------------------\n",
    "@tool\n",
    "def retrieve_game(query: str, n_results: int = 3):\n",
    "    \"\"\"\n",
    "    Semantic search: Finds the most relevant games from the vector DB.\n",
    "\n",
    "    Args:\n",
    "        query (str): A question about the game industry.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: Each result contains:\n",
    "            - Platform (e.g., Game Boy, PS5, Xbox 360)\n",
    "            - Name (name of the game)\n",
    "            - YearOfRelease\n",
    "            - Description\n",
    "    \"\"\"\n",
    "    print(\"üîé Retrieving from vector DB...\")\n",
    "    try:\n",
    "        collection = chroma_client.get_collection(\"games_collection_new\")\n",
    "\n",
    "        results = collection.query(\n",
    "            query_texts=query,\n",
    "            n_results=n_results,\n",
    "            include=[\"documents\", \"metadatas\"]\n",
    "        )\n",
    "\n",
    "        metadatas = results.get(\"metadatas\", [[]])[0]\n",
    "        documents = results.get(\"documents\", [[]])[0]\n",
    "\n",
    "        output = []\n",
    "        for meta, doc in zip(metadatas, documents):\n",
    "            output.append({\n",
    "                \"Platform\": meta.get(\"Platform\"),\n",
    "                \"Name\": meta.get(\"Name\"),\n",
    "                \"YearOfRelease\": meta.get(\"YearOfRelease\"),\n",
    "                \"Description\": meta.get(\"Description\"),\n",
    "                \"document\": doc\n",
    "            })\n",
    "\n",
    "        return {\n",
    "            \"data\": output\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return [{\"error\": str(e)}]\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "910dc945",
   "metadata": {},
   "source": [
    "#### Evaluate Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "id": "0d9d014b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T10:31:19.702897Z",
     "start_time": "2025-12-02T10:31:19.696899Z"
    }
   },
   "source": [
    "\n",
    "class EvaluationReport(BaseModel):\n",
    "    useful: bool\n",
    "    description: str\n",
    "\n",
    "@tool\n",
    "def evaluate_retrieval(question: str, retrieved_docs: list[dict]):\n",
    "    \"\"\"\n",
    "    LLM judge to evaluate whether retrieved docs are sufficient.\n",
    "    \"\"\"\n",
    "    print(\"üß† Evaluating retrieval...\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an evaluation assistant. Your task is to decide whether the retrieved documents are sufficient to answer the user's question.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Retrieved Documents:\n",
    "{json.dumps(retrieved_docs, indent=2)}\n",
    "\n",
    "Return ONLY valid JSON in this format:\n",
    "\n",
    "{{\"useful\": true, \"description\": \"...\"}}\n",
    "\"\"\"\n",
    "\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY, base_url=os.getenv(\"OPENAI_BASE_URL\"))\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=os.getenv(\"EVAL_MODEL\", \"gpt-4o-mini\"),\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.0\n",
    "    )\n",
    "\n",
    "    raw = resp.choices[0].message.content\n",
    "\n",
    "    # --- JSON extraction ---\n",
    "    try:\n",
    "        parsed = json.loads(raw)\n",
    "    except:\n",
    "        match = re.search(r\"\\{[\\s\\S]*\\}\", raw)\n",
    "        if not match:\n",
    "            return {\n",
    "                \"useful\": False,\n",
    "                \"description\": f\"Failed to extract JSON. Raw: {raw}\"\n",
    "            }\n",
    "        parsed = json.loads(match.group(0))\n",
    "\n",
    "    try:\n",
    "        report = EvaluationReport.model_validate(parsed)\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"useful\": False,\n",
    "            \"description\": f\"Invalid JSON schema: {str(e)}. Raw: {parsed}\"\n",
    "        }\n",
    "\n",
    "    return report.model_dump()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "c7935a26",
   "metadata": {},
   "source": [
    "#### Game Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "id": "2ad698aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T10:31:22.459287Z",
     "start_time": "2025-12-02T10:31:22.454868Z"
    }
   },
   "source": [
    "\n",
    "@tool\n",
    "def game_web_search(question: str, max_results: int = 3) -> dict:\n",
    "    \"\"\"\n",
    "    Uses Tavily client to search the web for a gaming-related question.\n",
    "    Returns a formatted, human-readable summary of sources.\n",
    "    \"\"\"\n",
    "    print(\"üåê Searching the web...\")\n",
    "    tavily = TavilyClient(api_key=TAVILY_API_KEY)\n",
    "    resp = tavily.search(\n",
    "        query=question,\n",
    "        include_answer=True,\n",
    "        max_results=max_results\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"answers\": resp.get(\"results\", []),\n",
    "    }\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "df844b3b",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T10:31:22.474023Z",
     "start_time": "2025-12-02T10:31:22.464365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tools = [\n",
    "    retrieve_game,\n",
    "    evaluate_retrieval,\n",
    "    game_web_search\n",
    "]\n",
    "\n",
    "uda_agent = Agent(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    tools=tools,\n",
    "    instructions=(\n",
    "        \"\"\"\n",
    "        You are a GameAgent, when a game-related question is asked, you MUST follow this pipeline:\n",
    "        1. Retrieve relevant documents from the local game database using the retrieve_game tool.\n",
    "        2. Evaluate the quality of the retrieved documents using the evaluate_retrieval tool.\n",
    "        3. If the retrieved documents are sufficient, provide a concise answer based on them.\n",
    "        4. If the documents are insufficient, search the web using the game_web_search tool. IF you use the `game_web_search` tool, then your FINAL ANSWER MUST follow this exact format:\n",
    "         Based on web search results:\n",
    "         - According to {title} ({url}): \"{content}\"\n",
    "         - According to {title} ({url}): \"{content}\"\n",
    "\n",
    "         The {title} MUST come from the web search result field \"title\".\n",
    "         The {content} MUST come from the result field \"content\".\n",
    "         The {url} MUST come from the field \"url\"\n",
    "         \"\"\"\n",
    "    ))"
   ],
   "id": "d02eabd06a4a3155",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T10:32:00.526379Z",
     "start_time": "2025-12-02T10:31:22.478901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "queries = [\n",
    "    \"What is the genre of the game Super Mario 64?\",\n",
    "    \"When was it released?\",\n",
    "    \"Why is Minecraft so popular?\",\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    print(\"\\n========================================\")\n",
    "    print(\"QUESTION:\", q)\n",
    "    print(\"========================================\\n\")\n",
    "\n",
    "    data = uda_agent.invoke(q, session_id='games_2')\n",
    "    result = data.get_final_state()\n",
    "    last_answer = next(\n",
    "        (m.content for m in reversed(result[\"messages\"])\n",
    "         if m.role == \"assistant\" and m.content),\n",
    "        None\n",
    "    )\n",
    "    print(last_answer)\n"
   ],
   "id": "848cf63dfe8e77ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "QUESTION: What is the genre of the game Super Mario 64?\n",
      "========================================\n",
      "\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "üîé Retrieving from vector DB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\building-agents\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "üß† Evaluating retrieval...\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "The genre of the game Super Mario 64 is a 3D platformer. It was released in 1996 for the Nintendo 64 and is known for setting new standards in the genre.\n",
      "\n",
      "========================================\n",
      "QUESTION: When was it released?\n",
      "========================================\n",
      "\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "Super Mario 64 was released in 1996.\n",
      "\n",
      "========================================\n",
      "QUESTION: Why is Minecraft so popular?\n",
      "========================================\n",
      "\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "üåê Searching the web...\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "Based on web search results:\n",
      "- According to \"Why Minecraft Became So Popular: Exploring the Phenomenon\" (https://game-sphere.medium.com/why-minecraft-became-so-popular-exploring-the-phenomenon-dba95109b86): \"Minecraft, one of the most popular video games of all time, has captured the hearts of millions of players worldwide and continues to attract new fans. Thanks to this community‚Äôs engagement, the game is continually updated and expanded, maintaining players‚Äô interest over time.\"\n",
      "- According to \"Why is Minecraft so popular given the game play and graphics seem ...\" (https://www.quora.com/Why-is-Minecraft-so-popular-given-the-game-play-and-graphics-seem-inferior-to-nowadays-games): \"It's simply because many people enjoy the freedom that Minecraft gives you.\"\n",
      "- According to \"Why is Minecraft still so popular? : r/gaming - Reddit\" (https://www.reddit.com/r/gaming/comments/t49cjm/why_is_minecraft_still_so_popular/): \"The free updates and the mods and community are pretty much the reason why Minecraft is still popular today.\"\n",
      "\n",
      "Minecraft's popularity can be attributed to its open-ended gameplay, creative freedom, active community, continuous updates, and the ability for players to build and explore in a world limited only by their imagination.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "f0a55081",
   "metadata": {},
   "source": [
    "### (Optional) Advanced"
   ]
  },
  {
   "cell_type": "code",
   "id": "eb83fbb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T10:32:01.378306Z",
     "start_time": "2025-12-02T10:32:01.341398Z"
    }
   },
   "source": [
    "import uuid\n",
    "from datetime import datetime\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# TODO: Update your agent with long-term memory\n",
    "# TODO: Convert the agent to be a state machine, with the tools being pre-defined nodes\n",
    "\n",
    "embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n",
    "long_term_memory = chroma_client.get_or_create_collection(name=\"long_term_memory\", embedding_function=embedding_fn)\n",
    "\n",
    "\n",
    "@tool\n",
    "def store_memory(query: str, answer: str):\n",
    "    \"\"\"\n",
    "    Store the final answer in long-term memory.\n",
    "    Both query and answer are saved together so that future recall works.\n",
    "    \"\"\"\n",
    "    print(\"üß† Storing memory...\")\n",
    "    memory_id = str(uuid.uuid4())\n",
    "\n",
    "    # Combine into one document (better for embedding & recall)\n",
    "    memory_document = f\"QUERY: {query}\\nANSWER: {answer}\"\n",
    "\n",
    "    long_term_memory.add(\n",
    "        documents=[memory_document],\n",
    "        ids=[memory_id],\n",
    "        metadatas=[{\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"query\": query\n",
    "        }]\n",
    "    )\n",
    "    return f\"Memory saved for query: {query}\"\n",
    "\n",
    "@tool\n",
    "def recall_relevant_memory(query: str, k: int = 1):\n",
    "    \"\"\"\n",
    "    Retrieves the top-k most relevant memories for the agent.\n",
    "    Returns a structured object including the source for traceability.\n",
    "    \"\"\"\n",
    "    print(\"üß† Recalling relevant memories...\")\n",
    "\n",
    "    results = long_term_memory.query(\n",
    "        query_texts=[query],\n",
    "        n_results=k\n",
    "    )\n",
    "\n",
    "    # No results case ‚Äî still return a source tag\n",
    "    if len(results[\"documents\"]) == 0 or len(results[\"documents\"][0]) == 0:\n",
    "        return {\n",
    "            \"source\": \"long_term_memory\",\n",
    "            \"found\": False,\n",
    "            \"memories\": [],\n",
    "            \"text\": \"No relevant memory found.\"\n",
    "        }\n",
    "\n",
    "    # Extract as list of strings\n",
    "    memories = results[\"documents\"][0]\n",
    "\n",
    "    return {\n",
    "        \"source\": \"long_term_memory\",\n",
    "        \"found\": True,\n",
    "        \"memories\": memories,\n",
    "        \"text\": \"\\n\".join([f\"- {m}\" for m in memories])\n",
    "    }\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T10:32:02.037835Z",
     "start_time": "2025-12-02T10:32:01.794593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "store_memory(\"Where can I play the game Zula?\", \"Zula can be played on PC as a free-to-play online game.\")\n",
    "recall_relevant_memory(\"Where can I play the game Zula?\")"
   ],
   "id": "72650bb4b85376be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Storing memory...\n",
      "üß† Recalling relevant memories...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'source': 'long_term_memory',\n",
       " 'found': True,\n",
       " 'memories': ['QUERY: Where can I play the game Zula?\\nANSWER: Zula can be played on PC as a free-to-play online game.'],\n",
       " 'text': '- QUERY: Where can I play the game Zula?\\nANSWER: Zula can be played on PC as a free-to-play online game.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T10:48:03.919759Z",
     "start_time": "2025-12-02T10:48:03.907852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "uda_agent_with_memory = Agent(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    tools=tools + [store_memory, recall_relevant_memory],\n",
    "    instructions=(\"\"\"\n",
    "You are a GameAgent with long-term memory.\n",
    "\n",
    "IMPORTANT EXECUTION RULES:\n",
    "- You MUST follow the pipeline exactly.\n",
    "- You MUST NOT output any natural-language answer directly unless it is the final step where memory already exists.\n",
    "- When memory must be stored, the answer MUST be returned inside the store_memory tool call.\n",
    "- NEVER mix normal text with a tool call in the same message.\n",
    "\n",
    "PIPELINE:\n",
    "\n",
    "1. ALWAYS call recall_relevant_memory(query).\n",
    "   - If memory is found (found=True):\n",
    "       ‚Üí Return the final user answer normally (no tool calls after this).\n",
    "       ‚Üí END.\n",
    "\n",
    "2. If found=False:\n",
    "       Call retrieve_game(query).\n",
    "\n",
    "3. Then call evaluate_retrieval.\n",
    "   - If \"useful\": true:\n",
    "        ‚Üí Create the final answer text.\n",
    "        ‚Üí Call store_memory with:\n",
    "              { \"query\": <user_query>, \"answer\": <final_answer> }\n",
    "        (The tool call IS your final message. Do NOT output the final answer outside the tool.)\n",
    "        ‚Üí END.\n",
    "   - If \"useful\": false:\n",
    "         ‚Üí Call game_web_search(query)\n",
    "\n",
    "\n",
    "5. After receiving search results from game_web_search:\n",
    "       ‚Üí Build the formatted answer string exactly like:\n",
    "            Based on web search results:\n",
    "            - According to {title} ({url}): \"{content}\"\n",
    "            - According to {title} ({url}): \"{content}\"\n",
    "\n",
    "         The {title} MUST come from the web search result field \"title\".\n",
    "         The {content} MUST come from the result field \"content\".\n",
    "         The {url} MUST come from the field \"url\"\n",
    "\n",
    "       ‚Üí Then call store_memory with:\n",
    "              { \"query\": <user_query>, \"answer\": <final_answer> }\n",
    "       (Again: ONLY output the tool call, do NOT output the final answer outside the tool.)\n",
    "       ‚Üí END.\n",
    "\n",
    "        \"\"\"))\n"
   ],
   "id": "d1dfa5d54a4ca4b2",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T10:49:22.109109Z",
     "start_time": "2025-12-02T10:48:34.479355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "queries = [\n",
    "    \"What is the genre of the game Halo Infinite\",\n",
    "    \"When was it released?\",\n",
    "    \"On which platforms can I play The Witcher 3?\",\n",
    "    \"What made FarmVille so successful?\"\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    print(\"\\n========================================\")\n",
    "    print(\"QUESTION:\", q)\n",
    "    print(\"========================================\\n\")\n",
    "\n",
    "    data = uda_agent_with_memory.invoke(q)\n",
    "    messages = data.get_final_state()[\"messages\"]\n",
    "    result = []\n",
    "    for msg in reversed(messages):\n",
    "        if msg.role == \"assistant\" and msg.content:\n",
    "            result = msg.content\n",
    "            break\n",
    "    print(result)\n",
    "\n",
    "\n"
   ],
   "id": "53a5dda920ccb513",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "QUESTION: What is the genre of the game Halo Infinite\n",
      "========================================\n",
      "\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "üß† Recalling relevant memories...\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "Halo Infinite is a first-person shooter game.\n",
      "\n",
      "========================================\n",
      "QUESTION: When was it released?\n",
      "========================================\n",
      "\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "üß† Recalling relevant memories...\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "Halo Infinite was released in 2021.\n",
      "\n",
      "========================================\n",
      "QUESTION: On which platforms can I play The Witcher 3?\n",
      "========================================\n",
      "\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "üß† Recalling relevant memories...\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "üîé Retrieving from vector DB...\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "üß† Evaluating retrieval...\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "üåê Searching the web...\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "üß† Storing memory...\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "Based on web search results:\n",
      "- According to The Witcher¬Æ 3: Wild Hunt ‚Äì Complete Edition - Humble Bundle (https://www.humblebundle.com/store/the-witcher-3-complete-edition?srsltid=AfmBOorTeY1PYKa8pdKIQL5822a4GMeXrP7LQQQHLb1_G97-vZU4jlNy): \"Windows, Nintendo Switch, Steam, Mac, Linux, Oculus Rift.\"\n",
      "- According to The Witcher 3: Wild Hunt - Wikipedia (https://en.wikipedia.org/wiki/The_Witcher_3:_Wild_Hunt): \"The Witcher 3: Wild Hunt was created for PlayStation 4 and Xbox One consoles.\"\n",
      "\n",
      "========================================\n",
      "QUESTION: What made FarmVille so successful?\n",
      "========================================\n",
      "\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "üß† Recalling relevant memories...\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "FarmVille was successful due to its social features, accessibility on Facebook, and engaging gameplay that appealed to a wide audience.\n"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "23393d2575091a37cff0d0e9e7479591a295495b26c3b2ebf9b64da572e02d85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
